import logging
import os
import time
import threading

import sys
import os
import torch
import numpy as np
import time
import traceback

import hydra
import torch
import numpy as np
import pandas as pd
import wandb
import matplotlib.pyplot as plt

from torch.func import vmap
from tqdm import tqdm
from omegaconf import OmegaConf

from omni_drones import init_simulation_app
from torchrl.data import CompositeSpec
from torchrl.envs.utils import set_exploration_type, ExplorationType
from omni_drones.utils.torchrl import SyncDataCollector
from omni_drones.utils.torchrl.transforms import (
    FromMultiDiscreteAction,
    FromDiscreteAction,
    ravel_composite,
    AttitudeController,
    RateController,
)
from omni_drones.utils.wandb import init_wandb
from omni_drones.utils.torchrl import RenderCallback, EpisodeStats
from omni_drones.learning import ALGOS

from setproctitle import setproctitle
from torchrl.envs.transforms import TransformedEnv, InitTracker, Compose


# å¯¼å…¥MPCç›¸å…³æ¨¡å—
from omni_drones.learning.mpc_components.Mpc import MPC
from omni_drones.learning.mpc_components.diff_acados import clear_solver_cache

def normalize_quaternion(quat):
    """å½’ä¸€åŒ–å››å…ƒæ•°"""
    norm = torch.norm(quat, dim=-1, keepdim=True)
    return quat / (norm + 1e-8)

def safe_numpy(tensor):
    """å®‰å…¨åœ°å°†tensorè½¬æ¢ä¸ºnumpyï¼Œå…¼å®¹CUDA"""
    if tensor.is_cuda:
        return tensor.detach().cpu().numpy()
    else:
        return tensor.detach().numpy()

def get_device():
    """è·å–å¯ç”¨çš„è®¾å¤‡"""
    if torch.cuda.is_available():
        return "cuda"
    else:
        return "cpu"

def create_test_initial_states(batch_size=2, device="cpu", use_real_data=False):
    """åˆ›å»ºæµ‹è¯•ç”¨çš„åˆå§‹çŠ¶æ€"""
    if use_real_data:
        # ä½¿ç”¨ä»å®é™…è®­ç»ƒæ—¥å¿—ä¸­æå–çš„çœŸå®æ•°æ®
        # è¿™äº›æ•°æ®æ¥è‡ªå®é™…çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¯¼è‡´QP solveré”™è¯¯
        real_states = [
            # æ¨ç†è®¡ç®—ç”¨çš„æ•°æ® (æ­£å¸¸å·¥ä½œ)
            # [0.9948, -0.6514, -0.1761, 0.6010, 0.0900, 0.2646, 0.7488, 0.7419, 0.6315, 0.4075],
            # è®­ç»ƒé˜¶æ®µç”¨çš„æ•°æ® (å¯¼è‡´QP solveré”™è¯¯)
            [0.5342, 0.9940, 0.4143, 0.2989, 0.2850, 0.8874, 0.2048, -2.4883, -0.3000, -6.7153],
        ]
        
        states = torch.zeros(batch_size, 10, device=device, dtype=torch.float32)
        for i in range(min(batch_size, len(real_states))):
            states[i] = torch.tensor(real_states[i], dtype=torch.float32, device=device)
            
        # å¦‚æœbatch_sizeå¤§äºreal_statesæ•°é‡ï¼Œå¤åˆ¶æœ€åä¸€ä¸ªçŠ¶æ€
        for i in range(len(real_states), batch_size):
            states[i] = states[len(real_states) - 1] + torch.randn(10, device=device) * 0.01
            
        # ç¡®ä¿å››å…ƒæ•°å½’ä¸€åŒ–
        for i in range(batch_size):
            quat = states[i, 3:7]
            states[i, 3:7] = normalize_quaternion(quat)
            
        return states
    
    # åŸå§‹çš„éšæœºç”Ÿæˆé€»è¾‘
    states = torch.zeros(batch_size, 10, device=device, dtype=torch.float32)
    
    # è®¾ç½®ä½ç½® (åœ¨åŸç‚¹é™„è¿‘çš„å°æ‰°åŠ¨)
    states[:, 0] = torch.randn(batch_size) * 0.1  # px
    states[:, 1] = torch.randn(batch_size) * 0.1  # py  
    states[:, 2] = torch.randn(batch_size) * 0.1 + 1.0  # pz (æ‚¬åœåœ¨1ç±³é«˜åº¦)
    
    # è®¾ç½®å››å…ƒæ•°ä¸ºæ¥è¿‘å•ä½å››å…ƒæ•°çš„å€¼
    states[:, 3] = 1.0  # qw
    states[:, 4] = torch.randn(batch_size) * 0.01  # qx (å°æ‰°åŠ¨)
    states[:, 5] = torch.randn(batch_size) * 0.01  # qy (å°æ‰°åŠ¨)
    states[:, 6] = torch.randn(batch_size) * 0.01  # qz (å°æ‰°åŠ¨)
    
    # å½’ä¸€åŒ–å››å…ƒæ•°
    quat = states[:, 3:7]
    states[:, 3:7] = normalize_quaternion(quat)
    
    # è®¾ç½®é€Ÿåº¦ (å°çš„åˆå§‹é€Ÿåº¦)
    states[:, 7] = torch.randn(batch_size) * 0.1  # vx
    states[:, 8] = torch.randn(batch_size) * 0.1  # vy
    states[:, 9] = torch.randn(batch_size) * 0.1  # vz
    
    return states

def create_test_cost_weights(batch_size=2, device="cpu", use_real_data=False):
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ä»£ä»·æƒé‡"""
    s_dim = 10  # çŠ¶æ€ç»´åº¦
    u_dim = 4   # æ§åˆ¶ç»´åº¦
    
    if use_real_data:
        # ä½¿ç”¨ä»å®é™…è®­ç»ƒæ—¥å¿—ä¸­æå–çš„çœŸå®æ•°æ®
        # è¿™äº›æ•°æ®æ¥è‡ªå®é™…çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¯¼è‡´QP solveré”™è¯¯
        real_Q_q = [
            # æ¨ç†è®¡ç®—ç”¨çš„Q_qæ•°æ® (æ­£å¸¸å·¥ä½œ)
            # å‰10ä¸ªæ˜¯Qæƒé‡ (çŠ¶æ€æƒé‡)ï¼Œå4ä¸ªæ˜¯Ræƒé‡ (æ§åˆ¶æƒé‡)
            # [10.7526, 10.5957, 10.6002, 10.7543, 10.8157, 10.7067, 10.6436, 10.8319, 10.6797, 10.6891, 10.8524, 10.6047, 10.6586, 10.6904],
            # è®­ç»ƒé˜¶æ®µç”¨çš„Q_qæ•°æ® (å¯¼è‡´QP solveré”™è¯¯)
            [10.4386, 10.7093, 10.7427, 10.7208, 11.0851, 10.3501, 10.7585, 10.5358, 10.8849, 10.8537, 10.7587, 10.4720, 10.7615, 11.3534],
        ]
        
        Q_q = torch.zeros(batch_size, s_dim + u_dim, device=device, dtype=torch.float32)
        for i in range(min(batch_size, len(real_Q_q))):
            Q_q[i] = torch.tensor(real_Q_q[i], dtype=torch.float32, device=device)
            
        # å¦‚æœbatch_sizeå¤§äºreal_Q_qæ•°é‡ï¼Œå¤åˆ¶æœ€åä¸€ä¸ªæƒé‡
        for i in range(len(real_Q_q), batch_size):
            Q_q[i] = Q_q[len(real_Q_q) - 1] + torch.randn(s_dim + u_dim, device=device) * 0.01
            
        # ç¡®ä¿æƒé‡ä¸ºæ­£
        Q_q = torch.abs(Q_q)
        
        return Q_q
    
    # åŸå§‹çš„éšæœºç”Ÿæˆé€»è¾‘
    # åˆ›å»ºQæƒé‡ (çŠ¶æ€æƒé‡)
    Q_base = torch.tensor([
        100.0, 100.0, 100.0,        # ä½ç½®æƒé‡ (px, py, pz)
        10.0, 10.0, 10.0, 10.0,     # å››å…ƒæ•°æƒé‡ (qw, qx, qy, qz)
        10.0, 10.0, 10.0             # é€Ÿåº¦æƒé‡ (vx, vy, vz)
    ], dtype=torch.float32, device=device)
    
    # åˆ›å»ºRæƒé‡ (æ§åˆ¶æƒé‡)
    R_base = torch.tensor([0.1, 0.1, 0.1, 0.1], dtype=torch.float32, device=device)
    
    # ä¸ºæ¯ä¸ªbatchæ·»åŠ å°çš„éšæœºæ‰°åŠ¨
    Q_diag = Q_base.unsqueeze(0).repeat(batch_size, 1)
    R_diag = R_base.unsqueeze(0).repeat(batch_size, 1)
    
    # æ·»åŠ å°çš„éšæœºæ‰°åŠ¨ä½¿æ¯ä¸ªbatchçš„æƒé‡ç•¥æœ‰ä¸åŒ
    Q_diag += torch.randn_like(Q_diag) * 0.01 * Q_base.unsqueeze(0)
    R_diag += torch.randn_like(R_diag) * 0.01 * R_base.unsqueeze(0)
    
    # ç¡®ä¿æƒé‡ä¸ºæ­£
    Q_diag = torch.abs(Q_diag)
    R_diag = torch.abs(R_diag)
    
    # åˆå¹¶Qå’ŒRæƒé‡
    Q_q = torch.cat([Q_diag, R_diag], dim=1)
    
    return Q_q

def test_problematic_case_specifically():
    """ä¸“é—¨æµ‹è¯•å¯¼è‡´QP solveré”™è¯¯çš„ç‰¹å®šæ•°æ®"""
    print("=" * 80)
    print("ğŸš¨ ä¸“é—¨æµ‹è¯•å¯¼è‡´QP solveré”™è¯¯çš„ç‰¹å®šæ•°æ®")
    print("=" * 80)
    
    device = get_device()  # è‡ªåŠ¨é€‰æ‹©å¯ç”¨è®¾å¤‡
    batch_size = 1  # ä½¿ç”¨å•ä¸ªæ ·æœ¬è¿›è¡Œè°ƒè¯•
    T = 0.016
    dt = 0.016
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ¸…é™¤æ±‚è§£å™¨ç¼“å­˜
    clear_solver_cache()
    
    print(f"åˆ›å»ºMPCå®ä¾‹ç”¨äºè°ƒè¯•")
    mpc = MPC(T=T, dt=dt, device=device)
    
    # ä½¿ç”¨å¯¼è‡´é—®é¢˜çš„ç‰¹å®šæ•°æ®
    problematic_state = torch.tensor([
        [0.5342, 0.9940, 0.4143, 0.2989, 0.2850, 0.8874, 0.2048, -2.4883, -0.3000, -6.7153]
    ], dtype=torch.float32, device=device)
    
    problematic_Q_q = torch.tensor([
        [10.4386, 10.7093, 10.7427, 10.7208, 11.0851, 10.3501, 10.7585, 10.5358, 10.8849, 10.8537, 10.7587, 10.4720, 10.7615, 11.3534]
    ], dtype=torch.float32, device=device)

    # # ä½¿ç”¨å¯¼è‡´é—®é¢˜çš„ç‰¹å®šæ•°æ®
    # problematic_state = torch.tensor([
    #     [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]
    # ], dtype=torch.float32, device=device)
    
    # problematic_Q_q = torch.tensor([
    #     [10.6899, 10.6724, 10.7156, 10.7129, 10.6692, 10.6841, 10.7064, 10.7039,
    #      10.6806, 10.7025, 10.7043, 10.6673, 10.6735, 10.6953]
    # ], dtype=torch.float32, device=device)
    
    # # å½’ä¸€åŒ–å››å…ƒæ•°
    # quat = problematic_state[0, 3:7]
    # problematic_state[0, 3:7] = normalize_quaternion(quat)
    
    print("\nğŸ“Š é—®é¢˜æ•°æ®åˆ†æ:")
    print(f"åˆå§‹çŠ¶æ€: {safe_numpy(problematic_state[0])}")
    print(f"  - ä½ç½®: [{problematic_state[0, 0]:.4f}, {problematic_state[0, 1]:.4f}, {problematic_state[0, 2]:.4f}]")
    print(f"  - å››å…ƒæ•°: [{problematic_state[0, 3]:.4f}, {problematic_state[0, 4]:.4f}, {problematic_state[0, 5]:.4f}, {problematic_state[0, 6]:.4f}]")
    print(f"  - é€Ÿåº¦: [{problematic_state[0, 7]:.4f}, {problematic_state[0, 8]:.4f}, {problematic_state[0, 9]:.4f}]")
    print(f"ä»£ä»·æƒé‡: {safe_numpy(problematic_Q_q[0])}")
    print(f"  - Qæƒé‡èŒƒå›´: [{torch.min(problematic_Q_q[0, :10]):.4f}, {torch.max(problematic_Q_q[0, :10]):.4f}]")
    print(f"  - Ræƒé‡èŒƒå›´: [{torch.min(problematic_Q_q[0, 10:]):.4f}, {torch.max(problematic_Q_q[0, 10:]):.4f}]")
    
    # æ£€æŸ¥æ•°æ®çš„æ•°å€¼ç‰¹æ€§
    print("\nğŸ” æ•°å€¼ç‰¹æ€§åˆ†æ:")
    quat_norm = torch.norm(problematic_state[0, 3:7])
    print(f"å››å…ƒæ•°èŒƒæ•°: {quat_norm:.6f}")
    
    vel_magnitude = torch.norm(problematic_state[0, 7:10])
    # print(f"é€Ÿåº¦å¤§å°: {vel_magnitude:.6f}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
    if vel_magnitude > 10.0:
        print("âš ï¸  è­¦å‘Š: é€Ÿåº¦å¼‚å¸¸å¤§!")
    
    if torch.any(torch.abs(problematic_state[0, 7:10]) > 5.0):
        print("âš ï¸  è­¦å‘Š: å­˜åœ¨å¤§çš„é€Ÿåº¦åˆ†é‡ï¼Œå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š")
    
    try:
        # 1. å…ˆæµ‹è¯•éè®­ç»ƒæ¨¡å¼
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•1: éè®­ç»ƒæ¨¡å¼")
        print("â”€" * 60)
        
        start_time = time.time()
        opt_u_eval, x_pred_eval = mpc.solve(problematic_Q_q, problematic_state, is_training=False)
        eval_time = time.time() - start_time
        
        print(f"âœ“ éè®­ç»ƒæ¨¡å¼æˆåŠŸ")
        print(f"  - æ±‚è§£æ—¶é—´: {eval_time:.4f}ç§’")
        print(f"  - æœ€ä¼˜æ§åˆ¶: {safe_numpy(opt_u_eval[0])}")
        
        # 2. æµ‹è¯•è®­ç»ƒæ¨¡å¼ï¼ˆè¿™é‡Œåº”è¯¥ä¼šå‡ºé”™ï¼‰
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•2: è®­ç»ƒæ¨¡å¼ (é¢„æœŸå‡ºç°QP solveré”™è¯¯)")
        print("â”€" * 60)
        
        Q_q_grad = problematic_Q_q.clone().detach().requires_grad_(True)
        x0_grad = problematic_state.clone().detach().requires_grad_(True)
        
        print("å¼€å§‹è®­ç»ƒæ¨¡å¼æ±‚è§£ï¼ˆå¯èƒ½å‡ºç°é”™è¯¯ï¼‰...")
        start_time = time.time()
        opt_u_train, x_pred_train = mpc.solve(Q_q_grad, x0_grad, is_training=True)
        train_time = time.time() - start_time
        
        print(f"âœ“ è®­ç»ƒæ¨¡å¼æ„å¤–æˆåŠŸï¼")
        print(f"  - æ±‚è§£æ—¶é—´: {train_time:.4f}ç§’")
        print(f"  - æœ€ä¼˜æ§åˆ¶: {safe_numpy(opt_u_train[0])}")
        
        # å¦‚æœåˆ°è¿™é‡Œæ²¡æœ‰é”™è¯¯ï¼Œè¿›è¡Œåå‘ä¼ æ’­æµ‹è¯•
        print("\næ‰§è¡Œåå‘ä¼ æ’­æµ‹è¯•...")
        target_u = torch.tensor([9.81, 0.0, 0.0, 0.0], device=device).expand_as(opt_u_train)
        loss = torch.sum((opt_u_train - target_u) ** 2)
        loss.backward()
        
        print(f"âœ“ åå‘ä¼ æ’­ä¹ŸæˆåŠŸï¼")
        if Q_q_grad.grad is not None:
            print(f"  - æ¢¯åº¦èŒƒæ•°: {torch.norm(Q_q_grad.grad):.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ¨¡å¼å‡ºç°é¢„æœŸé”™è¯¯: {e}")
        print("\nå®Œæ•´é”™è¯¯å †æ ˆ:")
        traceback.print_exc()
        
        # åˆ†æå¯èƒ½çš„é”™è¯¯åŸå› 
        print("\n" + "ğŸ” " * 20)
        print("é”™è¯¯åŸå› åˆ†æ")
        print("ğŸ” " * 20)
        
        error_str = str(e)
        if "QP solver returned error status 3" in error_str:
            print("âœ… æˆåŠŸé‡ç°äº† 'QP solver returned error status 3' é”™è¯¯!")
            print("\nå¯èƒ½çš„åŸå› :")
            print("1. å¤§çš„é€Ÿåº¦åˆ†é‡ (-2.4883, -6.7153) å¯¼è‡´åŠ¨åŠ›å­¦çº¿æ€§åŒ–ä¸å‡†ç¡®")
            print("2. å››å…ƒæ•° (0.2989, 0.2850, 0.8874, 0.2048) å¯èƒ½æ¥è¿‘å¥‡å¼‚é…ç½®")
            print("3. åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼ŒHessianè®¡ç®—å˜å¾—ç—…æ€")
            print("4. çº¦æŸæ¡ä»¶åœ¨è¿™ä¸ªçŠ¶æ€ä¸‹å˜å¾—ä¸å…¼å®¹")
            
            print("\nğŸ¯ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
            print("1. åœ¨MPCä¸­æ·»åŠ çŠ¶æ€é¢„å¤„ç†å’Œçº¦æŸ")
            print("2. å¢åŠ æ±‚è§£å™¨çš„æ­£åˆ™åŒ–å‚æ•°")
            print("3. ä½¿ç”¨æ›´é²æ£’çš„QPæ±‚è§£å™¨è®¾ç½®")
            print("4. æ·»åŠ çŠ¶æ€é¥±å’Œé™åˆ¶")
            print("5. åœ¨è®­ç»ƒå‰è¿›è¡ŒçŠ¶æ€æœ‰æ•ˆæ€§æ£€æŸ¥")
            
        return False

def test_mpc_forward_backward(use_real_data=False):
    """æµ‹è¯•MPCçš„å‰å‘å’Œåå‘ä¼ æ’­"""
    print("=" * 80)
    if use_real_data:
        print("MPCçµæ•åº¦æµ‹è¯• - ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®")
    else:
        print("MPCçµæ•åº¦æµ‹è¯• - ä½¿ç”¨éšæœºç”Ÿæˆæ•°æ®")
    print("=" * 80)
    
    # è®¾ç½®å‚æ•°
    device = "cuda"
    batch_size = 1
    T = 0.016  # é¢„æµ‹æ—¶åŸŸ
    dt = 0.016  # æ—¶é—´æ­¥é•¿
    
    torch.manual_seed(42)
    np.random.seed(42)
    
    # æ¸…é™¤æ±‚è§£å™¨ç¼“å­˜
    # clear_solver_cache()
    
    print(f"åˆ›å»ºMPCå®ä¾‹ (T={T}, dt={dt}, batch_size={batch_size})")
    mpc = MPC(T=T, dt=dt, device=device)
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        x0 = create_test_initial_states(batch_size, device, use_real_data)
        Q_q = create_test_cost_weights(batch_size, device, use_real_data)
        
        if use_real_data:
            print(f"\nä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®:")
            print(f"åˆå§‹çŠ¶æ€ç¤ºä¾‹ (ç¬¬ä¸€ä¸ªbatch):")
            print(f"  ä½ç½®: [{x0[0, 0]:.4f}, {x0[0, 1]:.4f}, {x0[0, 2]:.4f}]")
            print(f"  å››å…ƒæ•°: [{x0[0, 3]:.4f}, {x0[0, 4]:.4f}, {x0[0, 5]:.4f}, {x0[0, 6]:.4f}]")
            print(f"  é€Ÿåº¦: [{x0[0, 7]:.4f}, {x0[0, 8]:.4f}, {x0[0, 9]:.4f}]")
            print(f"ä»£ä»·æƒé‡ç¤ºä¾‹ (ç¬¬ä¸€ä¸ªbatch):")
            print(f"  Qæƒé‡: {safe_numpy(Q_q[0, :10])}")
            print(f"  Ræƒé‡: {safe_numpy(Q_q[0, 10:])}")
        
        # 1. æµ‹è¯•éè®­ç»ƒæ¨¡å¼ï¼ˆæ— çµæ•åº¦ï¼‰
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•1: éè®­ç»ƒæ¨¡å¼ (æ— çµæ•åº¦è®¡ç®—)")
        print("â”€" * 60)
        
        print(f"åˆå§‹çŠ¶æ€å½¢çŠ¶: {x0.shape}")
        print(f"ä»£ä»·æƒé‡å½¢çŠ¶: {Q_q.shape}")
        
        start_time = time.time()
        opt_u_eval, x_pred_eval = mpc.solve(Q_q, x0, is_training=False)
        eval_time = time.time() - start_time
        
        print(f"âœ“ éè®­ç»ƒæ¨¡å¼æ±‚è§£æˆåŠŸ")
        print(f"  - æ±‚è§£æ—¶é—´: {eval_time:.4f}ç§’")
        print(f"  - æœ€ä¼˜æ§åˆ¶å½¢çŠ¶: {opt_u_eval.shape}")
        print(f"  - é¢„æµ‹è½¨è¿¹å½¢çŠ¶: {x_pred_eval.shape}")
        print(f"  - æœ€ä¼˜æ§åˆ¶ç¤ºä¾‹: {safe_numpy(opt_u_eval[0])}")
        
        # 2. æµ‹è¯•è®­ç»ƒæ¨¡å¼ï¼ˆå¸¦çµæ•åº¦ï¼‰
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•2: è®­ç»ƒæ¨¡å¼ (å¸¦çµæ•åº¦è®¡ç®—)")
        print("â”€" * 60)
        
        # å‡†å¤‡éœ€è¦æ¢¯åº¦çš„å˜é‡
        Q_q_grad = Q_q.clone().detach().requires_grad_(True)
        x0_grad = x0.clone().detach().requires_grad_(True)
        
        print(f"Q_qæ¢¯åº¦å¯ç”¨: {Q_q_grad.requires_grad}")
        print(f"x0æ¢¯åº¦å¯ç”¨: {x0_grad.requires_grad}")
        
        # å‰å‘ä¼ æ’­
        print("\næ‰§è¡Œè®­ç»ƒæ¨¡å¼å‰å‘ä¼ æ’­...")
        start_time = time.time()
        opt_u_train, x_pred_train = mpc.solve(Q_q_grad, x0_grad, is_training=True)
        forward_time = time.time() - start_time
        
        print(f"âœ“ è®­ç»ƒæ¨¡å¼å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"  - å‰å‘ä¼ æ’­æ—¶é—´: {forward_time:.4f}ç§’")
        print(f"  - æœ€ä¼˜æ§åˆ¶å½¢çŠ¶: {opt_u_train.shape}")
        print(f"  - é¢„æµ‹è½¨è¿¹å½¢çŠ¶: {x_pred_train.shape}")
        
        # æ¯”è¾ƒä¸¤ç§æ¨¡å¼çš„ç»“æœ
        u_diff = torch.norm(opt_u_train - opt_u_eval).item()
        x_diff = torch.norm(x_pred_train - x_pred_eval).item()
        print(f"  - æ§åˆ¶å·®å¼‚ (è®­ç»ƒ vs éè®­ç»ƒ): {u_diff:.6f}")
        print(f"  - è½¨è¿¹å·®å¼‚ (è®­ç»ƒ vs éè®­ç»ƒ): {x_diff:.6f}")
        
        # 3. æµ‹è¯•åå‘ä¼ æ’­
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•3: åå‘ä¼ æ’­ (çµæ•åº¦è®¡ç®—)")
        print("â”€" * 60)
        
        # å®šä¹‰æŸå¤±å‡½æ•°
        target_u = torch.tensor([9.81, 0.0, 0.0, 0.0], device=device).expand_as(opt_u_train)
        target_pos = torch.zeros_like(x_pred_train[-1, :, :3])
        
        # è®¡ç®—æŸå¤±
        control_loss = torch.sum((opt_u_train - target_u) ** 2)
        position_loss = torch.sum((x_pred_train[-1, :, :3] - target_pos) ** 2)
        total_loss = control_loss + 0.1 * position_loss
        
        print(f"æ§åˆ¶æŸå¤±: {control_loss.item():.6f}")
        print(f"ä½ç½®æŸå¤±: {position_loss.item():.6f}")
        print(f"æ€»æŸå¤±: {total_loss.item():.6f}")
        
        # åå‘ä¼ æ’­
        print("\næ‰§è¡Œåå‘ä¼ æ’­...")
        start_time = time.time()
        total_loss.backward()
        backward_time = time.time() - start_time
        
        print(f"âœ“ åå‘ä¼ æ’­æˆåŠŸ")
        print(f"  - åå‘ä¼ æ’­æ—¶é—´: {backward_time:.4f}ç§’")
        
        # 4. æ£€æŸ¥æ¢¯åº¦
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•4: æ¢¯åº¦æ£€æŸ¥")
        print("â”€" * 60)
        
        success = True
        
        # æ£€æŸ¥Q_qçš„æ¢¯åº¦
        if Q_q_grad.grad is not None:
            q_grad = Q_q_grad.grad
            q_grad_norm = torch.norm(q_grad).item()
            q_grad_max = torch.max(torch.abs(q_grad)).item()
            
            print(f"Q_qæ¢¯åº¦ç»Ÿè®¡:")
            print(f"  - æ¢¯åº¦å½¢çŠ¶: {q_grad.shape}")
            print(f"  - æ¢¯åº¦èŒƒæ•°: {q_grad_norm:.6f}")
            print(f"  - æ¢¯åº¦æœ€å¤§å€¼: {q_grad_max:.6f}")
            print(f"  - æ¢¯åº¦ç¤ºä¾‹ (å‰5ä¸ªQå…ƒç´ ): {safe_numpy(q_grad[0, :5])}")
            print(f"  - æ¢¯åº¦ç¤ºä¾‹ (å‰4ä¸ªRå…ƒç´ ): {safe_numpy(q_grad[0, -4:])}")
            
            # æ£€æŸ¥æ¢¯åº¦æœ‰æ•ˆæ€§
            if torch.any(torch.isnan(q_grad)):
                print("âŒ Q_qæ¢¯åº¦åŒ…å«NaN")
                success = False
            elif torch.any(torch.isinf(q_grad)):
                print("âŒ Q_qæ¢¯åº¦åŒ…å«Inf")
                success = False
            elif q_grad_norm < 1e-10:
                print("âš  Q_qæ¢¯åº¦è¿‡å°ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
            else:
                print("âœ“ Q_qæ¢¯åº¦æ­£å¸¸")
        else:
            print("âŒ Q_qæ¢¯åº¦ä¸ºNone")
            success = False
        
        # æ£€æŸ¥x0çš„æ¢¯åº¦
        if x0_grad.grad is not None:
            x0_grad_norm = torch.norm(x0_grad.grad).item()
            x0_grad_max = torch.max(torch.abs(x0_grad.grad)).item()
            
            print(f"\nx0æ¢¯åº¦ç»Ÿè®¡:")
            print(f"  - æ¢¯åº¦å½¢çŠ¶: {x0_grad.grad.shape}")
            print(f"  - æ¢¯åº¦èŒƒæ•°: {x0_grad_norm:.6f}")
            print(f"  - æ¢¯åº¦æœ€å¤§å€¼: {x0_grad_max:.6f}")
            print(f"  - æ¢¯åº¦ç¤ºä¾‹: {safe_numpy(x0_grad.grad[0])}")
            
            if torch.any(torch.isnan(x0_grad.grad)):
                print("âŒ x0æ¢¯åº¦åŒ…å«NaN")
                success = False
            elif torch.any(torch.isinf(x0_grad.grad)):
                print("âŒ x0æ¢¯åº¦åŒ…å«Inf")
                success = False
            else:
                print("âœ“ x0æ¢¯åº¦æ­£å¸¸")
        else:
            print("âš  x0æ¢¯åº¦ä¸ºNone (å¯èƒ½æœªå®ç°ï¼Œè¿™æ˜¯æ­£å¸¸çš„)")
        
        # 5. ç®€å•çš„æ¢¯åº¦éªŒè¯
        print("\n" + "â”€" * 60)
        print("æµ‹è¯•5: ç®€å•æ•°å€¼æ¢¯åº¦éªŒè¯")
        print("â”€" * 60)
        
        # é€‰æ‹©ä¸€ä¸ªå‚æ•°è¿›è¡Œæ•°å€¼æ¢¯åº¦æ£€æŸ¥
        eps = 1e-4
        param_idx = (0, 0)  # ç¬¬ä¸€ä¸ªbatchçš„ç¬¬ä¸€ä¸ªQå‚æ•°
        
        # åŸå§‹æŸå¤±
        original_loss = total_loss.item()
        
        if Q_q_grad.grad is not None:
            analytical_grad = Q_q_grad.grad[param_idx].item()
        else:
            print("âŒ æ— æ³•è·å–è§£ææ¢¯åº¦è¿›è¡ŒéªŒè¯")
            analytical_grad = 0.0
        
        # æ­£å‘æ‰°åŠ¨
        Q_q_plus = Q_q.clone()
        Q_q_plus[param_idx] += eps
        opt_u_plus, x_pred_plus = mpc.solve(Q_q_plus, x0, is_training=False)
        target_u_plus = torch.tensor([9.81, 0.0, 0.0, 0.0], device=device).expand_as(opt_u_plus)
        target_pos_plus = torch.zeros_like(x_pred_plus[-1, :, :3])
        control_loss_plus = torch.sum((opt_u_plus - target_u_plus) ** 2)
        position_loss_plus = torch.sum((x_pred_plus[-1, :, :3] - target_pos_plus) ** 2)
        total_loss_plus = control_loss_plus + 0.1 * position_loss_plus
        
        # è´Ÿå‘æ‰°åŠ¨
        Q_q_minus = Q_q.clone()
        Q_q_minus[param_idx] -= eps
        opt_u_minus, x_pred_minus = mpc.solve(Q_q_minus, x0, is_training=False)
        target_u_minus = torch.tensor([9.81, 0.0, 0.0, 0.0], device=device).expand_as(opt_u_minus)
        target_pos_minus = torch.zeros_like(x_pred_minus[-1, :, :3])
        control_loss_minus = torch.sum((opt_u_minus - target_u_minus) ** 2)
        position_loss_minus = torch.sum((x_pred_minus[-1, :, :3] - target_pos_minus) ** 2)
        total_loss_minus = control_loss_minus + 0.1 * position_loss_minus
        
        # æ•°å€¼æ¢¯åº¦
        numerical_grad = (total_loss_plus.item() - total_loss_minus.item()) / (2 * eps)
        
        # æ¯”è¾ƒ
        relative_error = abs(analytical_grad - numerical_grad) / (abs(analytical_grad) + abs(numerical_grad) + 1e-8)
        
        print(f"å‚æ•° {param_idx} æ¢¯åº¦éªŒè¯:")
        print(f"  - è§£ææ¢¯åº¦: {analytical_grad:.6f}")
        print(f"  - æ•°å€¼æ¢¯åº¦: {numerical_grad:.6f}")
        print(f"  - ç›¸å¯¹è¯¯å·®: {relative_error:.4f}")
        
        if relative_error < 0.1:  # 10%å®¹å¿åº¦
            print("âœ“ æ¢¯åº¦éªŒè¯é€šè¿‡")
        else:
            print(f"âš  æ¢¯åº¦éªŒè¯æœ‰è¾ƒå¤§è¯¯å·® (ç›¸å¯¹è¯¯å·®: {relative_error:.4f})")
            # ä¸æ ‡è®°ä¸ºå¤±è´¥ï¼Œå› ä¸ºMPCæ±‚è§£å™¨çš„æ•°å€¼ç‰¹æ€§å¯èƒ½å¯¼è‡´è¯¯å·®
        
        # æ€»ç»“
        print("\n" + "=" * 80)
        print("æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        
        if success:
            print("ğŸ‰ æ‰€æœ‰å…³é”®æµ‹è¯•é€šè¿‡ï¼")
            print(f"âœ“ éè®­ç»ƒæ¨¡å¼æ±‚è§£æ­£å¸¸ ({eval_time:.4f}ç§’)")
            print(f"âœ“ è®­ç»ƒæ¨¡å¼æ±‚è§£æ­£å¸¸ ({forward_time:.4f}ç§’)")
            print(f"âœ“ åå‘ä¼ æ’­è®¡ç®—æ­£å¸¸ ({backward_time:.4f}ç§’)")
            print("âœ“ æ¢¯åº¦è®¡ç®—æ­£å¸¸ï¼Œæ— NaN/Inf")
            print("\neval_adjoint_solution_sensitivityåŠŸèƒ½å·¥ä½œæ­£å¸¸ï¼")
            return True
        else:
            print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            print("è¯·æ£€æŸ¥acadosæ±‚è§£å™¨é…ç½®å’Œçµæ•åº¦è®¡ç®—è®¾ç½®")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("\nå®Œæ•´é”™è¯¯å †æ ˆ:")
        traceback.print_exc()
        return False


@hydra.main(version_base=None, config_path=".", config_name="train")
def main(cfg):
    OmegaConf.register_new_resolver("eval", eval)
    OmegaConf.resolve(cfg)
    OmegaConf.set_struct(cfg, False)

    print("-------------------------------")
    print("Cfgs:",OmegaConf.to_yaml(cfg, resolve=True))
    print("-------------------------------")

    simulation_app = init_simulation_app(cfg)

    for i in range(1):

        print(f"å¼€å§‹ç¬¬{i}æ¬¡MPCçµæ•åº¦æµ‹è¯•...")
        
        # é¦–å…ˆä¸“é—¨æµ‹è¯•å¯¼è‡´é—®é¢˜çš„ç‰¹å®šæ•°æ®
        print("\n" + "ğŸ¯ " * 20)
        print("ç¬¬ä¸€é˜¶æ®µï¼šä¸“é—¨æµ‹è¯•å¯¼è‡´é—®é¢˜çš„ç‰¹å®šæ•°æ®")
        print("ğŸ¯ " * 20)
        success_specific = test_problematic_case_specifically()
            
        # ç„¶åä½¿ç”¨çœŸå®æ•°æ®é‡ç°é—®é¢˜
        print("\n" + "ğŸš¨ " * 20)
        print("ç¬¬ä¸‰é˜¶æ®µï¼šä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®é›†æµ‹è¯•")
        print("ğŸš¨ " * 20)
        print("âš ï¸  æ³¨æ„ï¼šè¿™å¯èƒ½ä¼šé‡ç° 'QP solver returned error status 3' é”™è¯¯")
        
        success_real = test_mpc_forward_backward(use_real_data=True)
        
        # if not success_real:
        #     print("\n" + "ğŸ” " * 20)
        #     print("è°ƒè¯•ä¿¡æ¯ï¼šQPæ±‚è§£å™¨é”™è¯¯åˆ†æ")
        #     print("ğŸ” " * 20)
        #     print("å¯èƒ½çš„åŸå› :")
        #     print("1. ä»£ä»·çŸ©é˜µæ¡ä»¶æ•°è¿‡å¤§æˆ–æ¥è¿‘å¥‡å¼‚")
        #     print("2. åˆå§‹çŠ¶æ€å¯¼è‡´ä¼˜åŒ–é—®é¢˜ä¸å¯è¡Œ")
        #     print("3. æ§åˆ¶çº¦æŸè¿‡äºä¸¥æ ¼")
        #     print("4. çµæ•åº¦è®¡ç®—æ—¶çš„æ•°å€¼ä¸ç¨³å®š")
        #     print("5. HessiançŸ©é˜µè®¡ç®—é—®é¢˜")
        #     print("\nå»ºè®®è°ƒè¯•æ­¥éª¤:")
        #     print("- æ£€æŸ¥ä»£ä»·æƒé‡çš„æ¡ä»¶æ•°")
        #     print("- éªŒè¯åˆå§‹çŠ¶æ€çš„å¯è¡Œæ€§")
        #     print("- å°è¯•æ”¾å®½æ±‚è§£å™¨æ”¶æ•›å®¹å¿åº¦")
        #     print("- ä½¿ç”¨ä¸åŒçš„QPæ±‚è§£å™¨ (FULL_CONDENSING_HPIPM)")
        #     print("- å¢åŠ æ­£åˆ™åŒ–å‚æ•° levenberg_marquardt")
        
        # # æ€»ç»“
        # print("\n" + "ğŸ“Š " * 20)
        # print("æµ‹è¯•æ€»ç»“")
        # print("ğŸ“Š " * 20)
        # print(f"ç‰¹å®šé—®é¢˜æ•°æ®æµ‹è¯•: {'âœ… é€šè¿‡' if success_specific else 'âŒ å¤±è´¥ (ç¬¦åˆé¢„æœŸ)'}")
        # # print(f"çœŸå®æ•°æ®æµ‹è¯•: {'âœ… é€šè¿‡' if success_real else 'âŒ å¤±è´¥'}")
        
        # if not success_specific:
        #     print("\nğŸ¯ ç»“è®º: æˆåŠŸé‡ç°äº†QP solveré”™è¯¯!")
        #     print("é—®é¢˜ç¡®å®å‡ºç°åœ¨ç‰¹å®šçš„è®­ç»ƒæ•°æ®ä¸Šï¼Œå…·ä½“æ˜¯:")
        #     print("- åˆå§‹çŠ¶æ€åŒ…å«å¤§çš„é€Ÿåº¦åˆ†é‡ (-2.4883, -6.7153)")
        #     print("- åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è®¡ç®—çµæ•åº¦æ—¶å¯¼è‡´æ•°å€¼ä¸ç¨³å®š")
        #     print("- éœ€è¦åœ¨MPCä¸­æ·»åŠ çŠ¶æ€é¢„å¤„ç†å’Œé²æ£’æ€§æ£€æŸ¥")

    simulation_app.close()


if __name__ == "__main__":
    main()
